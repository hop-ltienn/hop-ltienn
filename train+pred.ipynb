{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10739016,
          "sourceType": "datasetVersion",
          "datasetId": 6643056
        },
        {
          "sourceId": 10829256,
          "sourceType": "datasetVersion",
          "datasetId": 6640650
        },
        {
          "sourceId": 266373,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": false,
          "modelInstanceId": 222308,
          "modelId": 244068
        }
      ],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "papermill": {
      "default_parameters": {},
      "duration": 320.05508,
      "end_time": "2025-02-13T09:56:33.242965",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-02-13T09:51:13.187885",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hop-ltienn/hop-ltienn/blob/main/train%2Bpred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import các thư viện quan trọng\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T15:20:19.866419Z",
          "iopub.execute_input": "2025-02-23T15:20:19.866818Z",
          "iopub.status.idle": "2025-02-23T15:20:22.261484Z",
          "shell.execute_reply.started": "2025-02-23T15:20:19.866775Z",
          "shell.execute_reply": "2025-02-23T15:20:22.260765Z"
        },
        "id": "UO2AvpsbnP6K"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.load(\"/kaggle/input/dataflow/processed_data.pth\")\n",
        "padded_inputs = data[\"train\"]           #Dữ liệu đầu vào & đầu ra đã padding.\n",
        "padded_targets = data[\"test\"]\n",
        "attention_mask = data[\"mask\"]           #Đánh dấu vị trí có dữ liệu thực.\n",
        "continuous_cols = data['continuous']      #Các cột dữ liệu liên tục\n",
        "embedd_col=data['embedd']['col']            #Các cột cần embedding và giá trị của chúng.\n",
        "embedd_dict=data['embedd']['values']\n",
        "model_input_dim=len(continuous_cols)+8*len(embedd_col)          #Số chiều đầu vào của mô hình.\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T15:20:22.262320Z",
          "iopub.execute_input": "2025-02-23T15:20:22.262639Z",
          "iopub.status.idle": "2025-02-23T15:20:25.080321Z",
          "shell.execute_reply.started": "2025-02-23T15:20:22.262619Z",
          "shell.execute_reply": "2025-02-23T15:20:25.079647Z"
        },
        "id": "I9JO4x_-nP6O",
        "outputId": "ea593df1-fa4b-495d-866d-c16d6ac82037"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-2-9bdcc7278582>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  data = torch.load(\"/kaggle/input/dataflow/processed_data.pth\")\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------\n",
        "#Tạo Dataset & DataLoader\n",
        "# ------------------------------------------\n",
        "#BankSequenceDataset\n",
        "class BankSequenceDataset(Dataset):\n",
        "    def __init__(self, sequences, targets, attn_mask, cont_input_dim, cat_cols):\n",
        "        self.sequences = sequences\n",
        "        self.attn_mask = attn_mask\n",
        "        self.targets = targets\n",
        "        self.cont_input_dim = cont_input_dim\n",
        "        self.cat_cols = cat_cols\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.sequences.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        attn = self.attn_mask[idx]\n",
        "        target = self.targets[idx]\n",
        "\n",
        "        # Tách thành đặc trưng liên tục & danh mục\n",
        "        cont_features = seq[:, :self.cont_input_dim]\n",
        "        cat_features_raw = seq[:, self.cont_input_dim:]\n",
        "\n",
        "        cat_features = {}\n",
        "        for i, col in enumerate(self.cat_cols):\n",
        "            cat_features[col] = cat_features_raw[:, i].long()\n",
        "        return cont_features, cat_features, attn, target\n",
        "BATCH_SIZE = 64\n",
        "dataset = BankSequenceDataset(padded_inputs, padded_targets, attention_mask, len(continuous_cols), embedd_col)\n",
        "\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "#Chia thành tập train (90%) và validation(10%)\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.9 * total_size)\n",
        "val_size = total_size - train_size\n",
        "\n",
        "train_subset, val_subset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "#DataLoaders cho train & validation\n",
        "BATCH_SIZE = 64\n",
        "train_dataloader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T15:20:25.081558Z",
          "iopub.execute_input": "2025-02-23T15:20:25.081886Z",
          "iopub.status.idle": "2025-02-23T15:20:25.168908Z",
          "shell.execute_reply.started": "2025-02-23T15:20:25.081861Z",
          "shell.execute_reply": "2025-02-23T15:20:25.168116Z"
        },
        "id": "bhshxadonP6R"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Mô hình Transformer cho Dự đoán Chuỗi Giao Dịch\n",
        "\n",
        "## 1. Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class TransformerSeqModel(nn.Module):\n",
        "    def __init__(self, model_input_dim, embedd_dict, d_model, num_heads, num_layers, output_dim, embed_dim=8):\n",
        "\n",
        "\n",
        "        super(TransformerSeqModel, self).__init__()\n",
        "        ## Embedding các đặc trưng danh mục\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_categories, embed_dim)\n",
        "            for col, num_categories in embedd_dict.items()\n",
        "        })\n",
        "        # Chiếu đầu vào sang d_model\n",
        "        embedd_total_dim = embed_dim * len(embedd_dict)\n",
        "        self.input_proj = nn.Linear(model_input_dim, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(d_model, output_dim)\n",
        "\n",
        "    def forward(self, cont_features, cat_features, attn_mask):\n",
        "        cat_emb_list = []\n",
        "        for col, emb_layer in self.embeddings.items():\n",
        "            cat_emb = emb_layer(cat_features[col])\n",
        "            cat_emb_list.append(cat_emb)\n",
        "        if cat_emb_list:\n",
        "            cat_emb = torch.cat(cat_emb_list, dim=-1)\n",
        "            x = torch.cat([cont_features, cat_emb], dim=-1)\n",
        "        else:\n",
        "            x = cont_features\n",
        "        x = self.input_proj(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        key_padding_mask = (attn_mask == 0)\n",
        "        x = self.transformer_encoder(x, src_key_padding_mask=key_padding_mask)\n",
        "        out = self.fc(x)\n",
        "        return torch.sigmoid(out)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T15:20:31.464775Z",
          "iopub.execute_input": "2025-02-23T15:20:31.465127Z",
          "iopub.status.idle": "2025-02-23T15:20:31.482704Z",
          "shell.execute_reply.started": "2025-02-23T15:20:31.465098Z",
          "shell.execute_reply": "2025-02-23T15:20:31.481982Z"
        },
        "id": "eXarEiGdnP6S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Định nghĩa hyperparameters\n",
        "d_model = 64\n",
        "num_heads = 8\n",
        "num_layers = 4\n",
        "output_dim = 24\n",
        "#Khởi tạo và Nạp trọng số Mô hình\n",
        "model = TransformerSeqModel(model_input_dim, embedd_dict, d_model, num_heads, num_layers, output_dim, embed_dim=8)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model=model.to(device)\n",
        "model.load_state_dict(torch.load(\"/kaggle/input/dataflow_baseline_transformer/pytorch/default/8/focal.pth\"))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T15:20:36.679492Z",
          "iopub.execute_input": "2025-02-23T15:20:36.679788Z",
          "iopub.status.idle": "2025-02-23T15:20:36.875716Z",
          "shell.execute_reply.started": "2025-02-23T15:20:36.679764Z",
          "shell.execute_reply": "2025-02-23T15:20:36.874848Z"
        },
        "id": "vsmCk2OnnP6T",
        "outputId": "abb94fdf-9ed1-42be-9427-d6e4525c2a17"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-7-ba2cd5534f72>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"/kaggle/input/dataflow_baseline_transformer/pytorch/default/8/focal.pth\"))\n",
          "output_type": "stream"
        },
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Định Nghĩa Hàm Mất Mát & Tối Ưu Hóa\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Hàm Focal Loss với Label Smoothing và Masking\n",
        "def focal(outputs, targets, attn_mask, alpha=0.25, gamma=2.0, smoothing=0.1, reduction='mean'):\n",
        "    targets_smoothed = targets * (1 - smoothing) + 0.5 * smoothing\n",
        "    eps = 1e-6\n",
        "    outputs = torch.clamp(outputs, eps, 1.0 - eps)\n",
        "    bce_loss = - (targets_smoothed * torch.log(outputs) + (1 - targets_smoothed) * torch.log(1 - outputs))\n",
        "    pt = outputs * targets_smoothed + (1 - outputs) * (1 - targets_smoothed)\n",
        "    focal_weight = alpha * (1 - pt) ** gamma\n",
        "    loss = focal_weight * bce_loss\n",
        "    loss_masked = loss * attn_mask.unsqueeze(-1)\n",
        "\n",
        "    return loss_masked.sum() / attn_mask.sum() if reduction == 'mean' else loss_masked.sum()\n",
        "\n",
        "# Hàm BCE Loss với Label Smoothing\n",
        "def bce(outputs, targets, attn_mask, smoothing=0.1):\n",
        "    targets_smoothed = targets * (1 - smoothing) + 0.5 * smoothing\n",
        "    loss_fn = nn.BCELoss(reduction='none')\n",
        "    loss_raw = loss_fn(outputs, targets_smoothed)\n",
        "    loss_masked = loss_raw * attn_mask.unsqueeze(-1)\n",
        "\n",
        "    return loss_masked.sum() / attn_mask.sum()\n",
        "\n",
        "# Khởi tạo Optimizer và Scheduler\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "jGn8lhvenP6U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Định Nghĩa Hàm Đánh Giá MAP@5 & Early Stopping\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Hàm đánh giá Mean Average Precision @5\n",
        "def Map(y_true, y_pred, k=5):\n",
        "    num_samples = y_true.shape[0]\n",
        "    average_precisions = []\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        preds = np.argsort(-y_pred[i])[:k]\n",
        "        true_indices = np.where(y_true[i] == 1)[0]\n",
        "        if len(true_indices) == 0:\n",
        "            average_precisions.append(0)\n",
        "            continue\n",
        "        score = num_hits = 0.0\n",
        "        for j, pred in enumerate(preds):\n",
        "            if pred in true_indices:\n",
        "                num_hits += 1.0\n",
        "                score += num_hits / (j + 1.0)\n",
        "        average_precisions.append(score / min(len(true_indices), k))\n",
        "\n",
        "    return np.mean(average_precisions)\n",
        "\n",
        "# Early Stopping để dừng training khi không có cải thiện\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, delta=0.0, verbose=False, save_path=\"best_model.pth\"):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.verbose = verbose\n",
        "        self.save_path = save_path\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.best_loss = float('inf')\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss  # Đảo dấu vì muốn giảm val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        \"\"\"Lưu model nếu loss cải thiện.\"\"\"\n",
        "        if self.verbose:\n",
        "            print(f\"Validation loss improved to {val_loss:.4f}. Saving model to {self.save_path}\")\n",
        "        torch.save(model.state_dict(), self.save_path)\n",
        "        self.best_loss = val_loss"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T15:20:46.304412Z",
          "iopub.execute_input": "2025-02-23T15:20:46.304712Z",
          "iopub.status.idle": "2025-02-23T15:20:46.313367Z",
          "shell.execute_reply.started": "2025-02-23T15:20:46.304689Z",
          "shell.execute_reply": "2025-02-23T15:20:46.312348Z"
        },
        "id": "jnl4o-onnP6V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Huấn Luyện & Đánh Giá Mô Hình\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_and_eval(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    thres=0.5,\n",
        "    loss='focal',\n",
        "    epochs=10,\n",
        "    device=\"cpu\",\n",
        "    alpha=0.25,\n",
        "    gamma=2.0,\n",
        "    smoothing=0.1,\n",
        "    patience=3\n",
        "):\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True, save_path=\"best_model.pth\")\n",
        "    thres_tensor = torch.tensor(thres).to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # ---------------------------\n",
        "        # 1) Training Phase\n",
        "        # ---------------------------\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "        for cont_batch, cat_batch, attn_mask_batch, y_batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\"):\n",
        "            cont_batch, attn_mask_batch, y_batch = cont_batch.to(device), attn_mask_batch.to(device), y_batch.to(device)\n",
        "            cat_batch = {k: v.to(device) for k, v in cat_batch.items()}\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(cont_batch, cat_batch, attn_mask_batch)\n",
        "            loss = focal(outputs, y_batch, attn_mask_batch, alpha, gamma, smoothing) if loss == 'focal' else bce(outputs, y_batch, attn_mask_batch, smoothing)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "        # ---------------------------\n",
        "        # 2) Validation Phase\n",
        "        # ---------------------------\n",
        "        model.eval()\n",
        "        total_val_loss, all_outputs, all_targets = 0.0, [], []\n",
        "        with torch.no_grad():\n",
        "            for cont_batch, cat_batch, attn_mask_batch, y_batch in tqdm(val_dataloader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n",
        "                cont_batch, attn_mask_batch, y_batch = cont_batch.to(device), attn_mask_batch.to(device), y_batch.to(device)\n",
        "                cat_batch = {k: v.to(device) for k, v in cat_batch.items()}\n",
        "\n",
        "                outputs = model(cont_batch, cat_batch, attn_mask_batch)\n",
        "                val_loss = focal(outputs, y_batch, attn_mask_batch, alpha, gamma, smoothing)\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "                final_outputs = (outputs[:, -1, :] > thres_tensor).int()\n",
        "                final_targets = (y_batch[:, -1, :] > thres_tensor).int()\n",
        "                all_outputs.append(final_outputs.cpu().numpy())\n",
        "                all_targets.append(final_targets.cpu().numpy())\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "        all_outputs, all_targets = np.vstack(all_outputs), np.vstack(all_targets)\n",
        "        map7 = Map(all_targets, all_outputs, k=7) / y_batch.shape[0]\n",
        "\n",
        "        scheduler.step(avg_val_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] -> Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, MAP@7: {map7:.4f}\")\n",
        "\n",
        "        # ---------------------------\n",
        "        # 3) Early Stopping Check\n",
        "        # ---------------------------\n",
        "        early_stopping(avg_val_loss, model)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "id": "UabSUUJHnP6W"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 8. Train and Evaluate the Model\n",
        "\n",
        "train_and_eval(model, train_dataloader, val_dataloader, optimizer, scheduler,loss='focal', epochs=30, device=device, smoothing=0.1,patience=5)\n",
        "torch.save(model.state_dict(), \"focal.pth\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "iszA-AcJnP6Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Dự Đoán với Mô Hình Transformer\n",
        "\n",
        "## Hàm `predict`\n",
        "```python\n",
        "import torch\n",
        "\n",
        "def predict(model, dataloader, device=\"cpu\", thres=0.5):\n",
        "    \"\"\" Sinh dự đoán từ mô hình đã huấn luyện. \"\"\"\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    thres_tensor = torch.tensor(thres).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for cont_batch, cat_batch, attn_mask, _ in dataloader:\n",
        "            cont_batch, attn_mask = cont_batch.to(device), attn_mask.to(device)\n",
        "            cat_batch = {k: v.to(device) for k, v in cat_batch.items()}\n",
        "            outputs = model(cont_batch, cat_batch, attn_mask)\n",
        "            if outputs.dim() == 3:\n",
        "                outputs = (outputs[:, -1, :] > thres_tensor).int()\n",
        "            all_predictions.append(outputs)\n",
        "\n",
        "    return torch.cat(all_predictions, dim=0)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T15:20:52.032398Z",
          "iopub.execute_input": "2025-02-23T15:20:52.032704Z",
          "iopub.status.idle": "2025-02-23T15:20:52.038396Z",
          "shell.execute_reply.started": "2025-02-23T15:20:52.032679Z",
          "shell.execute_reply": "2025-02-23T15:20:52.037570Z"
        },
        "id": "EVUbZHFInP6Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "preds=predict(model,val_dataloader,device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T15:20:55.856565Z",
          "iopub.execute_input": "2025-02-23T15:20:55.856864Z",
          "iopub.status.idle": "2025-02-23T15:21:06.962140Z",
          "shell.execute_reply.started": "2025-02-23T15:20:55.856832Z",
          "shell.execute_reply": "2025-02-23T15:21:06.961398Z"
        },
        "id": "g5n6Y0a4nP6Z",
        "outputId": "12be20e3-76b4-4529-de77-f0cbadc64a21"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n  output = torch._nested_tensor_from_mask(\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "perf=[]\n",
        "for i in range(len(val_subset)):\n",
        "    m=Map(val_subset[i][-1][-1],preds[i].cpu())\n",
        "    perf.append(m)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T15:21:06.963257Z",
          "iopub.execute_input": "2025-02-23T15:21:06.963545Z",
          "iopub.status.idle": "2025-02-23T15:24:02.442149Z",
          "shell.execute_reply.started": "2025-02-23T15:21:06.963514Z",
          "shell.execute_reply": "2025-02-23T15:24:02.441134Z"
        },
        "id": "7mckjpzWnP6a",
        "outputId": "b3d631ac-24e3-434d-e807-959d2ca6fbc4"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-8-6eebf43f5962>:10: DeprecationWarning: Calling nonzero on 0d arrays is deprecated, as it behaves surprisingly. Use `atleast_1d(cond).nonzero()` if the old behavior was intended. If the context of this warning is of the form `arr[nonzero(cond)]`, just use `arr[cond]`.\n  true_indices = np.where(y_true[i] == 1)[0]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sum(perf)/len(perf)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T15:24:02.443990Z",
          "iopub.execute_input": "2025-02-23T15:24:02.444326Z",
          "iopub.status.idle": "2025-02-23T15:24:02.454168Z",
          "shell.execute_reply.started": "2025-02-23T15:24:02.444294Z",
          "shell.execute_reply": "2025-02-23T15:24:02.453490Z"
        },
        "id": "-Kow75pJnP6b",
        "outputId": "20d7e7cf-2c02-4fa6-d448-cb90983ba11d"
      },
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.04858423015298433"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}